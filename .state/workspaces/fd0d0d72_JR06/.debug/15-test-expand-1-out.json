{
  "accepted": true,
  "schemaName": "test_section_v1",
  "payload": {
    "schema_version": "test_section_v1",
    "role": "test-expand",
    "section_id": "structured-clone-tests",
    "type": "code",
    "file_path": "test_structured_clone.c",
    "content": "#include \"test.h\"\n#include \"structured_clone_context.h\"\n#include \"structured_clone_encoder.h\"\n#include \"structured_clone_executor.h\"\n#include <errno.h>\n#include <limits.h>\n#include <stdbool.h>\n#include <stdint.h>\n#include <stdlib.h>\n#include <string.h>\n#include <sys/types.h>\n#include <unistd.h>\n\n#define TRANSFER_FLAG_REGISTERED 0x1u\n#define TRANSFER_FLAG_DETACHED   0x2u\n#define TRANSFER_FLAG_IDENTITY   0x4u\n#define TRANSFER_FLAG_IN_PORT    0x8u\n#define TRANSFER_FLAG_COMMITTED  0x10u\n#define TRANSFER_FLAG_FAIL_COMMIT 0x20u\n\n#define SAB_FLAG_HAS_ATOMICS 0x1u\n\n#define TAG_PRIMITIVE 0x10u\n#define TAG_SEQUENCE 0x11u\n#define TAG_REFERENCE 0x12u\n#define TAG_ARRAYBUFFER 0x20u\n#define TAG_SHARED_ARRAYBUFFER 0x21u\n#define TAG_UNSUPPORTED 0xFFFFu\n\nstruct sc_primitive_value {\n    const uint8_t *bytes;\n    size_t length;\n};\n\nstruct sc_sequence_value {\n    const struct sc_value *const *children;\n    size_t child_count;\n};\n\nstruct test_port {\n    bool closed;\n    int id;\n};\n\nstruct commit_payload {\n    bool committed;\n};\n\nstatic uint32_t read_u32(const uint8_t *base, size_t offset)\n{\n    uint32_t val = 0;\n    memcpy(&val, base + offset, sizeof(val));\n    return val;\n}\n\nstatic void assert_transfer_entry(const struct sc_context *ctx,\n                                  size_t idx,\n                                  const void *handle,\n                                  size_t length,\n                                  unsigned int flag_mask)\n{\n    TEST_ASSERT(ctx->transfer_entries != NULL);\n    const struct sc_transferable_desc *entries =\n        (const struct sc_transferable_desc *)ctx->transfer_entries;\n    TEST_ASSERT(idx < ctx->transfer_count);\n    TEST_ASSERT_EQ(handle, entries[idx].handle);\n    TEST_ASSERT_EQ(length, entries[idx].length);\n    TEST_ASSERT((entries[idx].flags & flag_mask) == flag_mask);\n}\n\nstatic void test_sc_context_init_zeroes_arena(void)\n{\n    struct sc_context ctx = {\n        .arena_base = (void *)0xDEADBEEF,\n        .arena_size = 123,\n        .arena_used = 7,\n        .transfer_count = 3,\n        .transfer_entries = (void *)0xCAFEBABE\n    };\n\n    TEST_ASSERT_EQ(0, sc_context_init(&ctx, 256));\n    TEST_ASSERT(ctx.arena_base != NULL);\n    TEST_ASSERT_EQ(256u, ctx.arena_size);\n    TEST_ASSERT_EQ(0u, ctx.arena_used);\n    TEST_ASSERT_EQ(0u, ctx.transfer_count);\n    TEST_ASSERT(ctx.transfer_entries != NULL);\n\n    const uint8_t *arena = (const uint8_t *)ctx.arena_base;\n    for (size_t i = 0; i < 32; ++i) {\n        TEST_ASSERT_EQ(0u, arena[i]);\n    }\n\n    TEST_ASSERT_EQ(0, sc_context_free(&ctx));\n}\n\nstatic void test_sc_context_init_enomem_preserves_state(void)\n{\n    struct sc_context ctx = {\n        .arena_base = (void *)0x1,\n        .arena_size = 32,\n        .arena_used = 4,\n        .transfer_count = 2,\n        .transfer_entries = (void *)0x2\n    };\n\n    int rc = sc_context_init(&ctx, SIZE_MAX);\n    TEST_ASSERT_EQ(-ENOMEM, rc);\n    TEST_ASSERT_EQ((void *)0x1, ctx.arena_base);\n    TEST_ASSERT_EQ(32u, ctx.arena_size);\n    TEST_ASSERT_EQ(4u, ctx.arena_used);\n    TEST_ASSERT_EQ(2u, ctx.transfer_count);\n    TEST_ASSERT_EQ((void *)0x2, ctx.transfer_entries);\n}\n\nstatic void test_sc_context_register_transferable_records_handle(void)\n{\n    struct sc_context ctx;\n    TEST_ASSERT_EQ(0, sc_context_init(&ctx, 512));\n\n    uint8_t buffer[16] = {0};\n    struct sc_transferable_desc desc = {\n        .handle = buffer,\n        .length = sizeof(buffer),\n        .flags = 0\n    };\n\n    TEST_ASSERT_EQ(0, sc_context_register_transferable(&ctx, &desc));\n    TEST_ASSERT_EQ(1u, ctx.transfer_count);\n    assert_transfer_entry(&ctx, 0, buffer, sizeof(buffer), TRANSFER_FLAG_REGISTERED);\n\n    TEST_ASSERT_EQ(0, sc_context_free(&ctx));\n}\n\nstatic void test_sc_context_register_transferable_duplicate_returns_eexist(void)\n{\n    struct sc_context ctx;\n    TEST_ASSERT_EQ(0, sc_context_init(&ctx, 512));\n\n    uint8_t buffer[8] = {0};\n    struct sc_transferable_desc desc = {\n        .handle = buffer,\n        .length = sizeof(buffer),\n        .flags = 0\n    };\n\n    TEST_ASSERT_EQ(0, sc_context_register_transferable(&ctx, &desc));\n    int rc = sc_context_register_transferable(&ctx, &desc);\n    TEST_ASSERT_EQ(-EEXIST, rc);\n    TEST_ASSERT_EQ(1u, ctx.transfer_count);\n\n    TEST_ASSERT_EQ(0, sc_context_free(&ctx));\n}\n\nstatic void test_sc_context_free_idempotent(void)\n{\n    struct sc_context ctx;\n    TEST_ASSERT_EQ(0, sc_context_init(&ctx, 128));\n\n    uint8_t buffer[4] = {0};\n    struct sc_transferable_desc desc = {\n        .handle = buffer,\n        .length = sizeof(buffer),\n        .flags = 0\n    };\n    TEST_ASSERT_EQ(0, sc_context_register_transferable(&ctx, &desc));\n\n    TEST_ASSERT_EQ(0, sc_context_free(&ctx));\n    TEST_ASSERT_EQ(NULL, ctx.arena_base);\n    TEST_ASSERT_EQ(0u, ctx.arena_size);\n    TEST_ASSERT_EQ(0u, ctx.arena_used);\n    TEST_ASSERT_EQ(0u, ctx.transfer_count);\n    TEST_ASSERT_EQ(NULL, ctx.transfer_entries);\n\n    TEST_ASSERT_EQ(0, sc_context_free(&ctx));\n}\n\nstatic void test_sc_encode_value_depth_first_identity(void)\n{\n    struct sc_context ctx;\n    TEST_ASSERT_EQ(0, sc_context_init(&ctx, 512));\n\n    uint8_t encoded[256] = {0};\n    struct sc_encoded_buffer out = {\n        .data = encoded,\n        .length = 0,\n        .capacity = sizeof(encoded)\n    };\n\n    static const uint8_t left_bytes[] = { 'L' };\n    static const uint8_t right_bytes[] = { 'R', 'T' };\n    struct sc_primitive_value left_payload = { left_bytes, sizeof(left_bytes) };\n    struct sc_primitive_value right_payload = { right_bytes, sizeof(right_bytes) };\n    struct sc_value left = { &left_payload, TAG_PRIMITIVE };\n    struct sc_value right = { &right_payload, TAG_PRIMITIVE };\n    const struct sc_value *children[] = { &left, &right, &left };\n    struct sc_sequence_value seq = { children, 3 };\n    struct sc_value root = { &seq, TAG_SEQUENCE };\n\n    TEST_ASSERT_EQ(0, sc_encode_value(&ctx, &root, &out));\n    TEST_ASSERT(out.length > 0);\n    TEST_ASSERT_EQ(3u, ctx.transfer_count);\n    assert_transfer_entry(&ctx, 0, &root, 0, TRANSFER_FLAG_IDENTITY);\n    assert_transfer_entry(&ctx, 1, &left, 0, TRANSFER_FLAG_IDENTITY);\n    assert_transfer_entry(&ctx, 2, &right, 0, TRANSFER_FLAG_IDENTITY);\n\n    const uint8_t *bytes = encoded;\n    size_t offset = 0;\n    TEST_ASSERT_EQ(TAG_SEQUENCE, read_u32(bytes, offset));\n    offset += 4;\n    uint32_t seq_len = read_u32(bytes, offset);\n    offset += 4;\n    size_t seq_end = offset + seq_len;\n    TEST_ASSERT(seq_end <= out.length);\n\n    uint32_t child_count = read_u32(bytes, offset);\n    offset += 4;\n    TEST_ASSERT_EQ(3u, child_count);\n\n    TEST_ASSERT_EQ(TAG_PRIMITIVE, read_u32(bytes, offset));\n    offset += 4;\n    uint32_t child_len = read_u32(bytes, offset);\n    offset += 4;\n    TEST_ASSERT(child_len >= 4);\n    uint32_t payload_len = read_u32(bytes, offset);\n    offset += 4;\n    TEST_ASSERT_EQ(left_payload.length, payload_len);\n    TEST_ASSERT_EQ(left_bytes[0], bytes[offset]);\n    offset += payload_len;\n\n    TEST_ASSERT_EQ(TAG_PRIMITIVE, read_u32(bytes, offset));\n    offset += 4;\n    child_len = read_u32(bytes, offset);\n    offset += 4;\n    TEST_ASSERT(child_len >= 4);\n    payload_len = read_u32(bytes, offset);\n    offset += 4;\n    TEST_ASSERT_EQ(right_payload.length, payload_len);\n    TEST_ASSERT_EQ(right_bytes[0], bytes[offset]);\n    TEST_ASSERT_EQ(right_bytes[1], bytes[offset + 1]);\n    offset += payload_len;\n\n    TEST_ASSERT_EQ(TAG_REFERENCE, read_u32(bytes, offset));\n    offset += 4;\n    child_len = read_u32(bytes, offset);\n    offset += 4;\n    TEST_ASSERT_EQ(sizeof(uint32_t), child_len);\n    uint32_t ref_slot = read_u32(bytes, offset);\n    offset += 4;\n    TEST_ASSERT_EQ(1u, ref_slot);\n\n    TEST_ASSERT_EQ(seq_end, offset);\n\n    TEST_ASSERT_EQ(0, sc_context_free(&ctx));\n}\n\nstatic void test_sc_encode_value_rejects_unknown_tag(void)\n{\n    struct sc_context ctx;\n    TEST_ASSERT_EQ(0, sc_context_init(&ctx, 128));\n\n    uint8_t encoded[32] = {0};\n    struct sc_encoded_buffer out = {\n        .data = encoded,\n        .length = 0,\n        .capacity = sizeof(encoded)\n    };\n    struct sc_value invalid = { NULL, TAG_UNSUPPORTED };\n\n    TEST_ASSERT_EQ(-EINVAL, sc_encode_value(&ctx, &invalid, &out));\n    TEST_ASSERT_EQ(0u, out.length);\n    TEST_ASSERT_EQ(0u, ctx.transfer_count);\n\n    TEST_ASSERT_EQ(0, sc_context_free(&ctx));\n}\n\nstatic void test_sc_encode_arraybuffer_copies_payload_and_marks_detached(void)\n{\n    struct sc_context ctx;\n    TEST_ASSERT_EQ(0, sc_context_init(&ctx, 128));\n\n    uint8_t out_buf[128] = {0};\n    struct sc_encoded_buffer out = { out_buf, 0, sizeof(out_buf) };\n\n    uint8_t src_bytes[4] = { 1, 2, 3, 4 };\n    uint8_t expected[4];\n    memcpy(expected, src_bytes, sizeof(src_bytes));\n    struct sc_arraybuffer_desc src = { src_bytes, sizeof(src_bytes), 0 };\n\n    TEST_ASSERT_EQ(0, sc_encode_arraybuffer(&ctx, &src, &out));\n    TEST_ASSERT(out.length > 0);\n\n    const uint8_t *bytes = out_buf;\n    size_t offset = 0;\n    TEST_ASSERT_EQ(TAG_ARRAYBUFFER, read_u32(bytes, offset));\n    offset += 4;\n    uint32_t payload_len = read_u32(bytes, offset);\n    offset += 4;\n    TEST_ASSERT_EQ(sizeof(uint32_t) + sizeof(src_bytes), payload_len);\n    uint32_t byte_length = read_u32(bytes, offset);\n    offset += 4;\n    TEST_ASSERT_EQ(src.length, byte_length);\n    TEST_ASSERT_EQ(0, memcmp(bytes + offset, expected, sizeof(expected)));\n\n    assert_transfer_entry(&ctx, 0, src_bytes, sizeof(src_bytes), TRANSFER_FLAG_DETACHED);\n\n    TEST_ASSERT_EQ(0, sc_context_free(&ctx));\n}\n\nstatic void test_sc_encode_arraybuffer_rejects_emsgsize(void)\n{\n    struct sc_context ctx;\n    TEST_ASSERT_EQ(0, sc_context_init(&ctx, 64));\n\n    uint8_t out_buf[8] = {0};\n    struct sc_encoded_buffer out = { out_buf, 0, sizeof(out_buf) };\n    uint8_t src_bytes[16] = {0};\n    struct sc_arraybuffer_desc src = { src_bytes, sizeof(src_bytes), 0 };\n\n    TEST_ASSERT_EQ(-EMSGSIZE, sc_encode_arraybuffer(&ctx, &src, &out));\n    TEST_ASSERT_EQ(0u, out.length);\n    TEST_ASSERT_EQ(0u, ctx.transfer_count);\n\n    TEST_ASSERT_EQ(0, sc_context_free(&ctx));\n}\n\nstatic void test_sc_encode_shared_arraybuffer_handles_without_copy(void)\n{\n    struct sc_context ctx;\n    TEST_ASSERT_EQ(0, sc_context_init(&ctx, 128));\n\n    uint8_t out_buf[128] = {0};\n    struct sc_encoded_buffer out = { out_buf, 0, sizeof(out_buf) };\n\n    struct sc_shared_arraybuffer_desc sab = {\n        .handle = 42,\n        .length = 2048,\n        .flags = SAB_FLAG_HAS_ATOMICS\n    };\n\n    TEST_ASSERT_EQ(0, sc_encode_shared_arraybuffer(&ctx, &sab, &out));\n\n    const uint8_t *bytes = out_buf;\n    size_t offset = 0;\n    TEST_ASSERT_EQ(TAG_SHARED_ARRAYBUFFER, read_u32(bytes, offset));\n    offset += 4;\n    uint32_t payload_len = read_u32(bytes, offset);\n    offset += 4;\n    TEST_ASSERT_EQ(sizeof(int32_t) + sizeof(uint32_t) + sizeof(uint32_t), payload_len);\n    int32_t handle = (int32_t)read_u32(bytes, offset);\n    offset += 4;\n    TEST_ASSERT_EQ(sab.handle, handle);\n    uint32_t length = read_u32(bytes, offset);\n    offset += 4;\n    TEST_ASSERT_EQ(sab.length, length);\n\n    assert_transfer_entry(&ctx, 0, (void *)(intptr_t)sab.handle,\n                          sab.length, TRANSFER_FLAG_REGISTERED);\n\n    TEST_ASSERT_EQ(0, sc_context_free(&ctx));\n}\n\nstatic void test_sc_encode_shared_arraybuffer_requires_atomics(void)\n{\n    struct sc_context ctx;\n    TEST_ASSERT_EQ(0, sc_context_init(&ctx, 64));\n\n    uint8_t out_buf[32] = {0};\n    struct sc_encoded_buffer out = { out_buf, 0, sizeof(out_buf) };\n    struct sc_shared_arraybuffer_desc sab = {\n        .handle = 7,\n        .length = 128,\n        .flags = 0\n    };\n\n    TEST_ASSERT_EQ(-EPERM, sc_encode_shared_arraybuffer(&ctx, &sab, &out));\n    TEST_ASSERT_EQ(0u, out.length);\n    TEST_ASSERT_EQ(0u, ctx.transfer_count);\n\n    TEST_ASSERT_EQ(0, sc_context_free(&ctx));\n}\n\nstatic void test_sc_encode_postmessage_payload_builds_header(void)\n{\n    struct sc_context ctx;\n    TEST_ASSERT_EQ(0, sc_context_init(&ctx, 512));\n\n    uint8_t out_buf[256] = {0};\n    struct sc_encoded_buffer out = { out_buf, 0, sizeof(out_buf) };\n    static const uint8_t bytes[] = { 'o', 'k' };\n    struct sc_primitive_value prim = { bytes, sizeof(bytes) };\n    struct sc_value root = { &prim, TAG_PRIMITIVE };\n    struct sc_message_record record = {\n        .root = &root,\n        .transfer_list = NULL,\n        .transfer_count = 0\n    };\n\n    TEST_ASSERT_EQ(0, sc_encode_postmessage_payload(&ctx, &record, &out));\n    size_t header_len = sizeof(uint32_t) * 2;\n    TEST_ASSERT(out.length >= header_len);\n\n    const uint8_t *bytes_out = out_buf;\n    uint32_t payload_len = read_u32(bytes_out, 0);\n    uint32_t transfer_count = read_u32(bytes_out, sizeof(uint32_t));\n    TEST_ASSERT_EQ(record.transfer_count, transfer_count);\n    TEST_ASSERT_EQ(out.length - header_len, payload_len);\n\n    TEST_ASSERT_EQ(0, sc_context_free(&ctx));\n}\n\nstatic void test_sc_encode_postmessage_payload_overflow_returns_emsgsize(void)\n{\n    struct sc_context ctx;\n    TEST_ASSERT_EQ(0, sc_context_init(&ctx, 128));\n\n    uint8_t out_buf[8] = {0};\n    struct sc_encoded_buffer out = { out_buf, 0, sizeof(out_buf) };\n    static const uint8_t bytes[] = { 1, 2, 3, 4, 5, 6 };\n    struct sc_primitive_value prim = { bytes, sizeof(bytes) };\n    struct sc_value root = { &prim, TAG_PRIMITIVE };\n    struct sc_message_record record = {\n        .root = &root,\n        .transfer_list = NULL,\n        .transfer_count = 0\n    };\n\n    TEST_ASSERT_EQ(-EMSGSIZE, sc_encode_postmessage_payload(&ctx, &record, &out));\n    TEST_ASSERT_EQ(0u, out.length);\n\n    TEST_ASSERT_EQ(0, sc_context_free(&ctx));\n}\n\nstatic void test_sc_dispatch_to_worker_writes_and_signals(void)\n{\n    int queue_pipe[2];\n    int signal_pipe[2];\n    TEST_ASSERT_EQ(0, pipe(queue_pipe));\n    TEST_ASSERT_EQ(0, pipe(signal_pipe));\n\n    struct sc_worker_endpoint worker = {\n        .queue_fd = queue_pipe[1],\n        .signal_fd = signal_pipe[1],\n        .flags = 0\n    };\n\n    uint8_t payload_bytes[] = { 'i', 'p', 'c' };\n    struct sc_encoded_buffer payload = {\n        .data = payload_bytes,\n        .length = sizeof(payload_bytes),\n        .capacity = sizeof(payload_bytes)\n    };\n    struct sc_context ctx = {0};\n\n    TEST_ASSERT_EQ(0, sc_dispatch_to_worker(&ctx, &worker, &payload));\n\n    uint8_t queue_buf[8] = {0};\n    ssize_t n = read(queue_pipe[0], queue_buf, sizeof(queue_buf));\n    TEST_ASSERT_EQ((ssize_t)payload.length, n);\n    TEST_ASSERT_EQ(0, memcmp(queue_buf, payload_bytes, payload.length));\n\n    uint8_t signal_byte = 0;\n    TEST_ASSERT_EQ(1, read(signal_pipe[0], &signal_byte, 1));\n    TEST_ASSERT_EQ(1u, signal_byte);\n\n    close(queue_pipe[0]);\n    close(queue_pipe[1]);\n    close(signal_pipe[0]);\n    close(signal_pipe[1]);\n    TEST_ASSERT_EQ(0, sc_context_free(&ctx));\n}\n\nstatic void test_sc_transfer_ports_moves_handles_and_blocks_busy(void)\n{\n    struct sc_context ctx;\n    TEST_ASSERT_EQ(0, sc_context_init(&ctx, 256));\n\n    struct test_port port_state[2] = {\n        { .closed = false, .id = 1 },\n        { .closed = false, .id = 2 }\n    };\n\n    struct sc_transferable_desc ports[2] = {\n        { .handle = &port_state[0], .length = sizeof(struct test_port), .flags = 0 },\n        { .handle = &port_state[1], .length = sizeof(struct test_port), .flags = 0 }\n    };\n\n    TEST_ASSERT_EQ(0, sc_transfer_ports(&ctx, ports, 2));\n    TEST_ASSERT_EQ(NULL, ports[0].handle);\n    TEST_ASSERT_EQ(NULL, ports[1].handle);\n    TEST_ASSERT((ports[0].flags & TRANSFER_FLAG_IN_PORT) != 0);\n    TEST_ASSERT((ports[1].flags & TRANSFER_FLAG_IN_PORT) != 0);\n\n    struct sc_transferable_desc busy = {\n        .handle = &port_state[0],\n        .length = sizeof(struct test_port),\n        .flags = TRANSFER_FLAG_IN_PORT\n    };\n    TEST_ASSERT_EQ(-EBUSY, sc_transfer_ports(&ctx, &busy, 1));\n    TEST_ASSERT_EQ(&port_state[0], busy.handle);\n\n    TEST_ASSERT_EQ(0, sc_context_free(&ctx));\n}\n\nstatic void test_sc_commit_transfer_list_finalizes_handles(void)\n{\n    struct sc_context ctx;\n    TEST_ASSERT_EQ(0, sc_context_init(&ctx, 256));\n\n    struct commit_payload payloads[2] = {0};\n    struct sc_transferable_desc transfers[2] = {\n        { .handle = &payloads[0], .length = sizeof(payloads[0]), .flags = TRANSFER_FLAG_IN_PORT },\n        { .handle = &payloads[1], .length = sizeof(payloads[1]), .flags = TRANSFER_FLAG_IN_PORT }\n    };\n    struct sc_message_record record = {\n        .root = NULL,\n        .transfer_list = transfers,\n        .transfer_count = 2\n    };\n\n    TEST_ASSERT_EQ(0, sc_commit_transfer_list(&ctx, &record));\n    TEST_ASSERT_EQ(NULL, transfers[0].handle);\n    TEST_ASSERT_EQ(NULL, transfers[1].handle);\n    TEST_ASSERT((transfers[0].flags & TRANSFER_FLAG_COMMITTED) != 0);\n    TEST_ASSERT((transfers[1].flags & TRANSFER_FLAG_COMMITTED) != 0);\n\n    TEST_ASSERT_EQ(0, sc_context_free(&ctx));\n}\n\nstatic void test_sc_commit_transfer_list_rolls_back_on_failure(void)\n{\n    struct sc_context ctx;\n    TEST_ASSERT_EQ(0, sc_context_init(&ctx, 256));\n\n    struct commit_payload payloads[2] = {0};\n    struct sc_transferable_desc transfers[2] = {\n        { .handle = &payloads[0], .length = sizeof(payloads[0]), .flags = TRANSFER_FLAG_IN_PORT },\n        { .handle = &payloads[1], .length = sizeof(payloads[1]),\n          .flags = TRANSFER_FLAG_IN_PORT | TRANSFER_FLAG_FAIL_COMMIT }\n    };\n    struct sc_message_record record = {\n        .root = NULL,\n        .transfer_list = transfers,\n        .transfer_count = 2\n    };\n\n    TEST_ASSERT_EQ(-EIO, sc_commit_transfer_list(&ctx, &record));\n    TEST_ASSERT_EQ(&payloads[0], transfers[0].handle);\n    TEST_ASSERT_EQ(&payloads[1], transfers[1].handle);\n    TEST_ASSERT((transfers[0].flags & TRANSFER_FLAG_COMMITTED) == 0);\n\n    TEST_ASSERT_EQ(0, sc_context_free(&ctx));\n}\n\nint main(void)\n{\n    RUN_TEST(test_sc_context_init_zeroes_arena);\n    RUN_TEST(test_sc_context_init_enomem_preserves_state);\n    RUN_TEST(test_sc_context_register_transferable_records_handle);\n    RUN_TEST(test_sc_context_register_transferable_duplicate_returns_eexist);\n    RUN_TEST(test_sc_context_free_idempotent);\n    RUN_TEST(test_sc_encode_value_depth_first_identity);\n    RUN_TEST(test_sc_encode_value_rejects_unknown_tag);\n    RUN_TEST(test_sc_encode_arraybuffer_copies_payload_and_marks_detached);\n    RUN_TEST(test_sc_encode_arraybuffer_rejects_emsgsize);\n    RUN_TEST(test_sc_encode_shared_arraybuffer_handles_without_copy);\n    RUN_TEST(test_sc_encode_shared_arraybuffer_requires_atomics);\n    RUN_TEST(test_sc_encode_postmessage_payload_builds_header);\n    RUN_TEST(test_sc_encode_postmessage_payload_overflow_returns_emsgsize);\n    RUN_TEST(test_sc_dispatch_to_worker_writes_and_signals);\n    RUN_TEST(test_sc_transfer_ports_moves_handles_and_blocks_busy);\n    RUN_TEST(test_sc_commit_transfer_list_finalizes_handles);\n    RUN_TEST(test_sc_commit_transfer_list_rolls_back_on_failure);\n    return TEST_SUMMARY();\n}\n",
    "is_complete": true,
    "next_focus": ""
  }
}